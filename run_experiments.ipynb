{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in this notebook we will run some exepriements to figure out what the benchmark design should be.\n",
    "\n",
    "## Experiment 1: what context to include\n",
    "We have filtered the dataset into documents that work with wgpu (at least naga), are permissively licenses, and extract functions that contain both a comment directly before as well as a docstring directly at the top of the function body.\n",
    "we compare the four scenarios:\n",
    "- comment + header\n",
    "- comment + header + docstring (both)\n",
    "- header + docstring\n",
    "- header (none)\n",
    "it's 4x150 generations. We will use deepseek-coder (1.3b or 6.7b) as that showed promising signs before.\n",
    "\n",
    "This notebook will just run generations - the postprocessing might be done externally (like here? https://github.com/Vipitis/bigcode-evaluation-harness/tree/shadereval)\n",
    "or we throw something together tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, StopStringCriteria\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "experiment_ds = load_dataset(\"Vipitis/Shadereval-experiments-dev\")# , download_mode=\"force_redownload\")\n",
    "\n",
    "# model_id = \"deepseek-ai/deepseek-coder-6.7b-base\"\n",
    "model_id = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "stop_words = [\"\\nfloat\", \"\\nvec\", \"\\nint\", \"\\nmat\"] # should cover the really common cases to speed things up.\n",
    "\n",
    "# TODO: do we continue to use do_sample=False, because that has a huge impact on quality? -> more experiments\n",
    "# careful about the do_sample setting here, I changed it to True for a little speed comparison - but no luck.\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device, do_sample=False, stop_strings=stop_words, return_full_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cda3d54af4e492eb91d8cbec0428abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e478fbf14b9c4f87b303ee951e81ecdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m gen_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(experiment_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(m,k))): \u001b[38;5;66;03m# 10 just to test this locally...\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     gens \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m gens[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# inputs = tokenizer(row[experiment], return_tensors=\"pt\").to(device)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# generation = model.generate(**inputs, max_length=512, num_return_sequences=1, do_sample=False, stop_strings=stop_words, tokenizer=tokenizer, return_full_text=False)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# generated_text = tokenizer.decode(generation[0], skip_special_tokens=True)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:262\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1254\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m         )\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1261\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1260\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1261\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:349\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    350\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1911\u001b[0m     )\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1915\u001b[0m         input_ids,\n\u001b[0;32m   1916\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1917\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1918\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1919\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1920\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1921\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1922\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1923\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2652\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2653\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2654\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2655\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2656\u001b[0m )\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1174\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1171\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:978\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    967\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    968\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    969\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    975\u001b[0m         cache_position,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 978\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:715\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m        into the model\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    713\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 715\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m    718\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[0;32m    719\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    720\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    725\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    726\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:87\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m     85\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     86\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 87\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "k = min(len(experiment_ds[\"train\"])-m, 2+m)\n",
    "generations = {}\n",
    "for experiment in tqdm([\"input_both\", \"input_comment\", \"input_docstring\", \"input_none\"]):\n",
    "    gen_list = []\n",
    "    for row in tqdm(experiment_ds[\"train\"].select(range(m,k))): # 10 just to test this locally...\n",
    "        \n",
    "        gens = pipe(row[experiment], max_length=512, num_return_sequences=1, tokenizer=tokenizer)\n",
    "        generated_text = gens[0][\"generated_text\"]\n",
    "        # inputs = tokenizer(row[experiment], return_tensors=\"pt\").to(device)\n",
    "        # generation = model.generate(**inputs, max_length=512, num_return_sequences=1, do_sample=False, stop_strings=stop_words, tokenizer=tokenizer, return_full_text=False)\n",
    "        # generated_text = tokenizer.decode(generation[0], skip_special_tokens=True)\n",
    "        gen_list.append(generated_text)\n",
    "    generations[experiment] = gen_list\n",
    "\n",
    "# is an 1.3b model really ~10tok/s for me on A750? that seems really slow - maybe I am doing it wrong... it could also be caching in a bit. I updated transformers and acclelerate.\n",
    "# seems like stop_words don't work on xpu?\n",
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generations to a file\n",
    "import json\n",
    "with open(f\"exp1_generations_{m}-{k}.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(generations, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4dSXDd',\n",
       " 'comment': '// This is the big money function that makes the crazy fractally shape\\n',\n",
       " 'header': 'float DistanceToObject(vec3 p)\\n{',\n",
       " 'docstring': '\\n    //p += (1.0/p.y)*0.6;\\n\\n    // Rotate, but only the part that is on the side of rotDir',\n",
       " 'body': \"\\n    if (dot(p, rotDir) > 1.0) p *= rotMat;\\n\\n    // Repeat our position so we can carve out many cylindrical-like things from our solid\\n    vec3 rep = fract(p)-0.5;\\n    //final = max(final, -(length(rep.xz*rep.xz)*1.0 - 0.0326));\\n    float final = -(length(rep.xy*rep.xz) - 0.109);\\n    final = max(final, -(length(rep.zy) - 0.33));\\n\\n    //final = max(final, -(length(rep.xz*rep.xz) - 0.03));\\n    //final = max(final, -(length(rep.yz*rep.yz) - 0.03));\\n    //final = max(final, -(length(rep.xy*rep.xy) - 0.030266));\\n\\n    // Repeat the process of carving things out for smaller scales\\n    vec3 rep2 = fract(rep*2.0)-0.5;\\n    final = max(final, -(length(rep2.xz)*0.5 - 0.125));\\n    final = max(final, -(length(rep2.xy)*0.5 - 0.125));\\n    final = max(final, -(length(rep2.zy)*0.5 - 0.125));\\n\\n    vec3 rep3 = fract(rep2*3.0)-0.5;\\n    final = max(final, -(length(rep3.xz)*0.1667 - 0.25*0.1667));\\n    final = max(final, -(length(rep3.xy)*0.1667 - 0.25*0.1667));\\n    final = max(final, -(length(rep3.zy)*0.1667 - 0.25*0.1667));\\n\\n#ifdef TOO_MUCH_FRACTAL\\n    vec3 rep4 = fract(rep3*3.0)-0.5;\\n    final = max(final, -(length(rep4.xz)*0.0555 - 0.25*0.0555));\\n    final = max(final, -(length(rep4.xy)*0.0555 - 0.25*0.0555));\\n    final = max(final, -(length(rep4.yz)*0.0555 - 0.25*0.0555));\\n\\n    vec3 rep5 = fract(rep4*3.0)-0.5;\\n    final = max(final, -(length(rep5.xz)*0.0185 - 0.25*0.0185));\\n    final = max(final, -(length(rep5.xy)*0.0185 - 0.25*0.0185));\\n    final = max(final, -(length(rep5.yz)*0.0185 - 0.25*0.0185));\\n#endif\\n\\n    // Cut out stuff outside of outer sphere\\n    final = max(final, (length(p) - outerSphereRad));\\n    // Carve out inner sphere\\n    final = max(final, -(length(p) - 2.8));\\n    //final = max(final, abs(p.x) - 2.0);\\t// for that space station look\\n    //final = (length(p) - outerSphereRad);\\t// for debugging texture and lighting\\n    // Slice the object in a 3d grid so it can rotate like a rubik's cube\\n    float slice = 0.02;\\n    vec3 grid = -abs(fract(p.xyz)) + slice;\\n    final = max(final, grid.x);\\n    final = max(final, grid.y);\\n    final = max(final, grid.z);\\n    //final = min(final, abs(p.y));\\n    return final;\\n}\",\n",
       " 'full_code': '/*--------------------------------------------------------------------------------------\\nLicense CC0 - http://creativecommons.org/publicdomain/zero/1.0/\\nTo the extent possible under law, the author(s) have dedicated all copyright and related and neighboring rights to this software to the public domain worldwide. This software is distributed without any warranty.\\n----------------------------------------------------------------------------------------\\n^ This means do ANYTHING YOU WANT with this code. Because we are programmers, not lawyers.\\n-Otavio Good\\n*/\\n\\n// This will lower the framerate, but looks kinda cool\\n//#define TOO_MUCH_FRACTAL\\n\\n//#define MOVING_SUN\\nfloat outerSphereRad = 3.5;\\n\\n// noise functions\\nfloat Hash1d(float u)\\n{\\n    return fract(sin(u)*143.9);\\t// scale this down to kill the jitters\\n}\\nfloat Hash2d(vec2 uv)\\n{\\n    float f = uv.x + uv.y * 37.0;\\n    return fract(sin(f)*104003.9);\\n}\\nfloat Hash3d(vec3 uv)\\n{\\n    float f = uv.x + uv.y * 37.0 + uv.z * 521.0;\\n    return fract(sin(f)*110003.9);\\n}\\nfloat mixP(float f0, float f1, float a)\\n{\\n    return mix(f0, f1, a*a*(3.0-2.0*a));\\n}\\nconst vec2 zeroOne = vec2(0.0, 1.0);\\nfloat noise2d(vec2 uv)\\n{\\n    vec2 fr = fract(uv.xy);\\n    vec2 fl = floor(uv.xy);\\n    float h00 = Hash2d(fl);\\n    float h10 = Hash2d(fl + zeroOne.yx);\\n    float h01 = Hash2d(fl + zeroOne);\\n    float h11 = Hash2d(fl + zeroOne.yy);\\n    return mixP(mixP(h00, h10, fr.x), mixP(h01, h11, fr.x), fr.y);\\n}\\nfloat noise(vec3 uv)\\n{\\n    vec3 fr = fract(uv.xyz);\\n    vec3 fl = floor(uv.xyz);\\n    float h000 = Hash3d(fl);\\n    float h100 = Hash3d(fl + zeroOne.yxx);\\n    float h010 = Hash3d(fl + zeroOne.xyx);\\n    float h110 = Hash3d(fl + zeroOne.yyx);\\n    float h001 = Hash3d(fl + zeroOne.xxy);\\n    float h101 = Hash3d(fl + zeroOne.yxy);\\n    float h011 = Hash3d(fl + zeroOne.xyy);\\n    float h111 = Hash3d(fl + zeroOne.yyy);\\n    return mixP(\\n        mixP(mixP(h000, h100, fr.x),\\n             mixP(h010, h110, fr.x), fr.y),\\n        mixP(mixP(h001, h101, fr.x),\\n             mixP(h011, h111, fr.x), fr.y)\\n        , fr.z);\\n}\\n\\nfloat PI=3.14159265;\\n\\n// Variables for animating and rotating the sides of the object\\nfloat chunkAnim = 0.0;\\nmat3 rotMat;\\nvec3 rotDir;\\nfloat rotAmount;\\n\\nvec3 saturate(vec3 a) { return clamp(a, 0.0, 1.0); }\\nvec2 saturate(vec2 a) { return clamp(a, 0.0, 1.0); }\\nfloat saturate(float a) { return clamp(a, 0.0, 1.0); }\\n\\n\\n// This function basically is a procedural environment map that makes the sun\\nvec3 sunCol = vec3(258.0, 208.0, 100.0) / 4255.0;\\nvec3 GetSunColorReflection(vec3 rayDir, vec3 sunDir)\\n{\\n\\tvec3 localRay = normalize(rayDir);\\n\\tfloat dist = 1.0 - (dot(localRay, sunDir) * 0.5 + 0.5);\\n\\tfloat sunIntensity = 0.015 / dist;\\n\\tsunIntensity = pow(sunIntensity, 0.3)*100.0;\\n\\n    sunIntensity += exp(-dist*12.0)*300.0;\\n\\tsunIntensity = min(sunIntensity, 40000.0);\\n\\treturn sunCol * sunIntensity*0.0425;\\n}\\nvec3 GetSunColorSmall(vec3 rayDir, vec3 sunDir)\\n{\\n\\tvec3 localRay = normalize(rayDir);\\n\\tfloat dist = 1.0 - (dot(localRay, sunDir) * 0.5 + 0.5);\\n\\tfloat sunIntensity = 0.05 / dist;\\n    sunIntensity += exp(-dist*12.0)*300.0;\\n\\tsunIntensity = min(sunIntensity, 40000.0);\\n\\treturn sunCol * sunIntensity*0.025;\\n}\\n\\n// This spiral noise works by successively adding and rotating sin waves while increasing frequency.\\n// It should work the same on all computers since it\\'s not based on a hash function like some other noises.\\n// It can be much faster than other noise functions if you\\'re ok with some repetition.\\nconst float nudge = 0.71;\\t// size of perpendicular vector\\nfloat normalizer = 1.0 / sqrt(1.0 + nudge*nudge);\\t// pythagorean theorem on that perpendicular to maintain scale\\n// Total hack of the spiral noise function to get a rust look\\nfloat RustNoise3D(vec3 p)\\n{\\n    float n = 0.0;\\n    float iter = 1.0;\\n    float pn = noise(p*0.125);\\n    pn += noise(p*0.25)*0.5;\\n    pn += noise(p*0.5)*0.25;\\n    pn += noise(p*1.0)*0.125;\\n    for (int i = 0; i < 7; i++)\\n    {\\n        //n += (sin(p.y*iter) + cos(p.x*iter)) / iter;\\n        float wave = saturate(cos(p.y*0.25 + pn) - 0.998);\\n       // wave *= noise(p * 0.125)*1016.0;\\n        n += wave;\\n        p.xy += vec2(p.y, -p.x) * nudge;\\n        p.xy *= normalizer;\\n        p.xz += vec2(p.z, -p.x) * nudge;\\n        p.xz *= normalizer;\\n        iter *= 1.4733;\\n    }\\n    return n*500.0;\\n}\\n\\nvec3 camPos = vec3(0.0), camFacing;\\nvec3 camLookat=vec3(0,0.0,0);\\n\\n// This is the big money function that makes the crazy fractally shape\\nfloat DistanceToObject(vec3 p)\\n{\\n    //p += (1.0/p.y)*0.6;\\n\\n    // Rotate, but only the part that is on the side of rotDir\\n    if (dot(p, rotDir) > 1.0) p *= rotMat;\\n\\n    // Repeat our position so we can carve out many cylindrical-like things from our solid\\n    vec3 rep = fract(p)-0.5;\\n    //final = max(final, -(length(rep.xz*rep.xz)*1.0 - 0.0326));\\n    float final = -(length(rep.xy*rep.xz) - 0.109);\\n    final = max(final, -(length(rep.zy) - 0.33));\\n\\n    //final = max(final, -(length(rep.xz*rep.xz) - 0.03));\\n    //final = max(final, -(length(rep.yz*rep.yz) - 0.03));\\n    //final = max(final, -(length(rep.xy*rep.xy) - 0.030266));\\n\\n    // Repeat the process of carving things out for smaller scales\\n    vec3 rep2 = fract(rep*2.0)-0.5;\\n    final = max(final, -(length(rep2.xz)*0.5 - 0.125));\\n    final = max(final, -(length(rep2.xy)*0.5 - 0.125));\\n    final = max(final, -(length(rep2.zy)*0.5 - 0.125));\\n\\n    vec3 rep3 = fract(rep2*3.0)-0.5;\\n    final = max(final, -(length(rep3.xz)*0.1667 - 0.25*0.1667));\\n    final = max(final, -(length(rep3.xy)*0.1667 - 0.25*0.1667));\\n    final = max(final, -(length(rep3.zy)*0.1667 - 0.25*0.1667));\\n\\n#ifdef TOO_MUCH_FRACTAL\\n    vec3 rep4 = fract(rep3*3.0)-0.5;\\n    final = max(final, -(length(rep4.xz)*0.0555 - 0.25*0.0555));\\n    final = max(final, -(length(rep4.xy)*0.0555 - 0.25*0.0555));\\n    final = max(final, -(length(rep4.yz)*0.0555 - 0.25*0.0555));\\n\\n    vec3 rep5 = fract(rep4*3.0)-0.5;\\n    final = max(final, -(length(rep5.xz)*0.0185 - 0.25*0.0185));\\n    final = max(final, -(length(rep5.xy)*0.0185 - 0.25*0.0185));\\n    final = max(final, -(length(rep5.yz)*0.0185 - 0.25*0.0185));\\n#endif\\n\\n    // Cut out stuff outside of outer sphere\\n    final = max(final, (length(p) - outerSphereRad));\\n    // Carve out inner sphere\\n    final = max(final, -(length(p) - 2.8));\\n    //final = max(final, abs(p.x) - 2.0);\\t// for that space station look\\n    //final = (length(p) - outerSphereRad);\\t// for debugging texture and lighting\\n    // Slice the object in a 3d grid so it can rotate like a rubik\\'s cube\\n    float slice = 0.02;\\n    vec3 grid = -abs(fract(p.xyz)) + slice;\\n    final = max(final, grid.x);\\n    final = max(final, grid.y);\\n    final = max(final, grid.z);\\n    //final = min(final, abs(p.y));\\n    return final;\\n}\\n\\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\\n{\\n\\t// ---------------- First, set up the camera rays for ray marching ----------------\\n\\tvec2 uv = fragCoord.xy/iResolution.xy * 2.0 - 1.0;\\n\\n\\t// Camera up vector.\\n\\tvec3 camUp=vec3(0,1,0);\\n\\n\\t// Camera lookat.\\n\\tcamLookat=vec3(0,0.0,0);\\n\\n    // debugging camera\\n    float mx=iMouse.x/iResolution.x*PI*2.0 + iTime * 0.166;\\n\\tfloat my=-iMouse.y/iResolution.y*10.0 + sin(iTime * 0.3)*0.8+0.1;//*PI/2.01;\\n    // move camera in and out of the sphere\\n    float smallTime = iTime*0.2;\\n    float inOut = pow(abs(-cos(smallTime)), 0.6)* sign(-cos(smallTime));\\n\\tcamPos += vec3(cos(my)*cos(mx),sin(my),cos(my)*sin(mx))*(3.35+inOut*2.0);\\n\\n    // add randomness to camera for depth-of-field look close up.\\n    //camPos += vec3(Hash2d(uv)*0.91, Hash2d(uv+37.0), Hash2d(uv+47.0))*0.01;\\n\\n\\t// Camera setup.\\n\\tvec3 camVec=normalize(camLookat - camPos);\\n\\tvec3 sideNorm=normalize(cross(camUp, camVec));\\n\\tvec3 upNorm=cross(camVec, sideNorm);\\n\\tvec3 worldFacing=(camPos + camVec);\\n\\tvec3 worldPix = worldFacing + uv.x * sideNorm * (iResolution.x/iResolution.y) + uv.y * upNorm;\\n\\tvec3 relVec = normalize(worldPix - camPos);\\n\\n\\t// -------------------------------- animate ---------------------------------------\\n    float localTime = iTime*0.5;\\n    float floorTime = floor(localTime);\\n    float zeroToOne = max(0.0,fract(localTime)*1.0-0.0);// *4.0-3.0);\\n    // This is the 0..1 for the rotation\\n    chunkAnim = smoothstep(0.0, 1.0, zeroToOne);\\n    // This is for brightening the outer sphere when a rotation happens\\n    float pulse = saturate(-log(zeroToOne*30.0)+2.0);\\n\\n    //float mft = mod(floorTime, 6.0);\\n    // Let\\'s make it rotate a random part every time\\n    float mft = Hash1d(floorTime * 2.34567);\\n    mft = floor(mft * 5.9999);\\t// get a random [0..6) integer\\n    // randomize where the rotation slice is\\n    float uglyRand = Hash1d(floorTime*1.234567);\\n    uglyRand = floor(uglyRand*2.999);\\t// get a random [0..3) integer\\n    uglyRand = 1.0 / (uglyRand + 1.0);\\n\\n    // Check which axis we should rotate on and make a matrix for it.\\n    if (mft <= 1.0)\\n    {\\n        rotAmount = PI;\\n        float cos = cos(chunkAnim * rotAmount);\\n        float sin = sin(chunkAnim * rotAmount);\\n        rotMat = mat3(1.0, 0.0, 0.0,\\n                      0.0, cos, sin,\\n                      0.0, -sin, cos);\\n        rotDir = vec3(uglyRand, 0.0, 0.0);\\n    }\\n    else if (mft <= 3.0)\\n    {\\n        rotAmount = PI;\\n        float cos = cos(chunkAnim * rotAmount);\\n        float sin = sin(chunkAnim * rotAmount);\\n        rotMat = mat3(cos, 0.0, -sin,\\n                      0.0, 1.0, 0.0,\\n                      sin, 0.0, cos);\\n        rotDir = vec3(0.0, uglyRand, 0.0);\\n    }\\n    else\\n    {\\n        rotAmount = PI;\\n        float cos = cos(chunkAnim * rotAmount);\\n        float sin = sin(chunkAnim * rotAmount);\\n        rotMat = mat3(cos, sin, 0.0,\\n                      -sin, cos, 0.0,\\n                      0.0, 0.0, 1.0);\\n        rotDir = vec3(0.0, 0.0, uglyRand);\\n    }\\n    if (mod(floorTime, 2.0) == 0.0) rotDir = -rotDir;\\n\\n\\t// --------------------------------------------------------------------------------\\n\\tfloat dist = 0.15;\\n\\tfloat t = 0.2 + Hash2d(uv)*0.1;\\t// fade things close to the camera\\n\\tfloat inc = 0.02;\\n\\tfloat maxDepth = 11.0;\\n\\tvec3 pos = vec3(0,0,0);\\n    float glow = 0.0;\\n\\t// ray marching time\\n    for (int i = 0; i < 110; i++)\\t// This is the count of the max times the ray actually marches.\\n    {\\n        if ((t > maxDepth) || (abs(dist) < 0.001)) break;\\n        pos = camPos + relVec * t;\\n        // *******************************************************\\n        // This is _the_ function that defines the \"distance field\".\\n        // It\\'s really what makes the scene geometry.\\n        // *******************************************************\\n        dist = DistanceToObject(pos);\\n        // Do some tricks for marching so that we can march the inner glow sphere\\n        float lp = length(pos);\\n        //if (lp > outerSphereRad + 0.9) break;\\n        float inv = max(0.0, 0.1*dist / lp - 0.1);\\n        dist = min(max(0.15,lp*0.6 - 0.1), dist);\\n        glow += inv;//0.001\\n        glow += 0.0025;\\n\\n        // no deformations messing up the distance function this time. Hurray for getting the math right!\\n        t += dist;//*0.9995;\\t// because deformations mess up distance function.\\n    }\\n\\n\\t// --------------------------------------------------------------------------------\\n\\t// Now that we have done our ray marching, let\\'s put some color on this geometry.\\n\\n#ifdef MOVING_SUN\\n\\tvec3 sunDir = normalize(vec3(sin(iTime*0.047-1.5), cos(iTime*0.047-1.5), -0.5));\\n#else\\n\\tvec3 sunDir = normalize(vec3(0.93, 1.0, -1.5));\\n#endif\\n\\tvec3 finalColor = vec3(0.0);\\n\\n\\t// If a ray actually hit the object, let\\'s light it.\\n\\tif (abs(dist) < 0.75)\\n    //if (t <= maxDepth)\\n\\t{\\n        // calculate the normal from the distance field. The distance field is a volume, so if you\\n        // sample the current point and neighboring points, you can use the difference to get\\n        // the normal.\\n        vec3 smallVec = vec3(0.0025, 0, 0);\\n        vec3 normalU = vec3(dist - DistanceToObject(pos - smallVec.xyy),\\n                           dist - DistanceToObject(pos - smallVec.yxy),\\n                           dist - DistanceToObject(pos - smallVec.yyx));\\n\\n        vec3 normal = normalize(normalU);\\n\\n        // calculate 2 ambient occlusion values. One for global stuff and one\\n        // for local stuff\\n        float ambientS = 1.0;\\n        //ambientS *= saturate(DistanceToObject(pos + normal * 0.1)*10.0);\\n        ambientS *= saturate(DistanceToObject(pos + normal * 0.2)*5.0);\\n        ambientS *= saturate(DistanceToObject(pos + normal * 0.4)*2.5);\\n        ambientS *= saturate(DistanceToObject(pos + normal * 0.8)*1.25);\\n        float ambient = ambientS * saturate(DistanceToObject(pos + normal * 1.6)*1.25*0.5);\\n        ambient *= saturate(DistanceToObject(pos + normal * 3.2)*1.25*0.25);\\n        ambient *= saturate(DistanceToObject(pos + normal * 6.4)*1.25*0.125);\\n        //ambient = max(0.05, pow(ambient, 0.3));\\t// tone down ambient with a pow and min clamp it.\\n        ambient = saturate(ambient);\\n\\n        // Trace a ray toward the sun for sun shadows\\n        float sunShadow = 1.0;\\n        float iter = 0.05;\\n\\t\\tfor (int i = 0; i < 30; i++)\\n        {\\n            vec3 tempPos = pos + sunDir * iter;\\n            //if (dot(tempPos, tempPos) > outerSphereRad*outerSphereRad+0.8) break;\\n            if (iter > outerSphereRad + outerSphereRad) break;\\n            float tempDist = DistanceToObject(tempPos);\\n\\t        sunShadow *= saturate(tempDist*50.0);\\n            if (tempDist <= 0.0) break;\\n            //iter *= 1.5;\\t// constant is more reliable than distance-based???\\n            iter += max(0.01, tempDist)*1.0;\\n        }\\n        sunShadow = saturate(sunShadow);\\n\\n        // calculate the reflection vector for highlights\\n        vec3 ref = reflect(relVec, normal);\\n\\n        // make sure the texture gets rotated along with the geometry.\\n        vec3 posTex = pos;\\n        if (dot(pos, rotDir) > 1.0) posTex = pos * rotMat;\\n        posTex = abs(posTex);\\t// make texture symetric so it doesn\\'t pop after rotation\\n\\n        // make a few frequencies of noise to give it some texture\\n        float n =0.0;\\n        n += noise(posTex*32.0);\\n        n += noise(posTex*64.0);\\n        n += noise(posTex*128.0);\\n        n += noise(posTex*256.0);\\n        n += noise(posTex*512.0);\\n        n *= 0.8;\\n        normal = normalize(normal + n*0.1);\\n\\n        // ------ Calculate texture color  ------\\n        vec3 texColor = vec3(0.95, 1.0, 1.0);\\n        vec3 rust = vec3(0.65, 0.25, 0.1) - noise(posTex*128.0);\\n        texColor *= smoothstep(texColor, rust, vec3(saturate(RustNoise3D(posTex*8.0))-0.2));\\n\\n        // make outer edge a little brighter\\n\\t\\ttexColor += (1.0 - vec3(19.0, 5.0, 2.0) * length(normalU))*ambientS;\\n        // apply noise\\n        texColor *= vec3(1.0)*n*0.05;\\n        texColor *= 0.7;\\n        texColor = saturate(texColor);\\n\\n        // ------ Calculate lighting color ------\\n        // Start with sun color, standard lighting equation, and shadow\\n        vec3 lightColor = vec3(0.6) * saturate(dot(sunDir, normal)) * sunShadow;\\n        // weighted average the near ambient occlusion with the far for just the right look\\n        float ambientAvg = (ambient*3.0 + ambientS) * 0.25;\\n        // a red and blue light coming from different directions\\n        lightColor += (vec3(1.0, 0.2, 0.4) * saturate(-normal.z *0.5+0.5))*pow(ambientAvg, 0.5);\\n        lightColor += (vec3(0.1, 0.5, 0.99) * saturate(normal.y *0.5+0.5))*pow(ambientAvg, 0.5);\\n        // blue glow light coming from the glow in the middle of the sphere\\n        lightColor += vec3(0.3, 0.5, 0.9) * saturate(dot(-pos, normal))*pow(ambientS, 0.3);\\n//        lightColor *= ambient;\\n        lightColor *= 4.0;\\n\\n        // finally, apply the light to the texture.\\n        finalColor = texColor * lightColor;\\n        // sun reflection to make it look metal\\n        finalColor += vec3(1.0)*pow(n,4.0)* GetSunColorSmall(ref, sunDir) * sunShadow;// * ambientS;\\n        // fog that fades to reddish plus the sun color so that fog is brightest towards sun\\n        //finalColor = mix(vec3(1.0, 0.41, 0.41)*skyMultiplier + min(vec3(0.25),GetSunColorSmall(relVec, sunDir))*2.0*sunSet, finalColor, exp(-t*0.003));\\n        // pulse the outer edge color when something is about to rotate\\n        if (dot(pos, rotDir) > 1.0) finalColor += vec3(0.2, 1.4, 0.8)*pulse*saturate(0.000001 / pow(abs(length(pos)-outerSphereRad), 2.0))*2.0;\\n\\t}\\n    else\\n    {\\n        // Our ray trace hit nothing, so draw sky.\\n        //finalColor = saturate(GetSunColorSmall(relVec, sunDir)*0.95-0.01);\\n    }\\n    // add the ray marching glow\\n    finalColor += vec3(0.3, 0.5, 0.9) * glow;\\n\\n    // vignette?\\n    finalColor *= vec3(1.0) * saturate(1.0 - length(uv/2.5));\\n    finalColor *= 1.3;\\n\\n\\t// output the final color with sqrt for \"gamma correction\"\\n\\tfragColor = vec4(sqrt(clamp(finalColor, 0.0, 1.0)),1.0);\\n}\\n\\n\\n',\n",
       " 'func_bytes': [4341, 4412, 4444, 4534, 6672],\n",
       " 'has_comment': True,\n",
       " 'has_docstring': True,\n",
       " 'model_ctx': '// This is the big money function that makes the crazy fractally shape\\nfloat DistanceToObject(vec3 p)\\n{// This is the big money function that makes the crazy fractally shape\\n',\n",
       " 'needed': True,\n",
       " 'status': 'valid',\n",
       " 'input_both': '// This is the big money function that makes the crazy fractally shape\\nfloat DistanceToObject(vec3 p)\\n{\\n    //p += (1.0/p.y)*0.6;\\n\\n    // Rotate, but only the part that is on the side of rotDir',\n",
       " 'input_comment': '// This is the big money function that makes the crazy fractally shape\\nfloat DistanceToObject(vec3 p)\\n{',\n",
       " 'input_docstring': 'float DistanceToObject(vec3 p)\\n{\\n    //p += (1.0/p.y)*0.6;\\n\\n    // Rotate, but only the part that is on the side of rotDir',\n",
       " 'input_none': 'float DistanceToObject(vec3 p)\\n{',\n",
       " '__index_level_0__': 114}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_ds[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Do we include the main function as a 1-shot task?\n",
    "Motivation: LiveCodeBench does 1-shot for base models, this might help them understand the language that is used (via syntax clues), and also gives them an idea on whats available outside of the context we provide.\n",
    "every shader will have a main function, and we likely don't want to generate them anyways...\n",
    "the dataset for this is not prepared. But it would be only non main functions, and we have an additional columns in the dataset for the main function (or at least it's start-byte, as there should be nothing past it).\n",
    "open questions: do we add comments to explain this? do we list the function names for all other stuff available (and later down also in common tab?)\n",
    "main issue: the mainImage function is at the bottom, we would mess up the order. Not too bad for transformers as it's all parallel and they might not understand this strict definition... we have to see the results.\n",
    "\n",
    "alternative: give the model the whole context- but context length will be a problem, FIM is likely the goal - but not all models support that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this experiment (but prepare the data first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: do_sample True or False? also what generation parameters\n",
    "this is motivated by observations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
